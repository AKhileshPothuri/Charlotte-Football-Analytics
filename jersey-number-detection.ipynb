{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":30198,"databundleVersionId":2544621,"sourceType":"competition"},{"sourceId":1734434,"sourceType":"datasetVersion","datasetId":1029470},{"sourceId":2530556,"sourceType":"datasetVersion","datasetId":1532363},{"sourceId":7020940,"sourceType":"datasetVersion","datasetId":4037329}],"dockerImageVersionId":30121,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NFL Jersey Number Recognition to Track Players","metadata":{}},{"cell_type":"code","source":"import sys\nfrom pathlib import Path\nimport os\nfrom datetime import datetime\nimport time\nimport random\nimport cv2 as cv\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.utils import class_weight\nfrom tqdm import tqdm\nimport random\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:49:52.157194Z","iopub.execute_input":"2023-12-01T15:49:52.157516Z","iopub.status.idle":"2023-12-01T15:49:57.818655Z","shell.execute_reply.started":"2023-12-01T15:49:52.157441Z","shell.execute_reply":"2023-12-01T15:49:57.817707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"TensorFlow version:\", tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:49:57.820061Z","iopub.execute_input":"2023-12-01T15:49:57.820367Z","iopub.status.idle":"2023-12-01T15:49:57.825158Z","shell.execute_reply.started":"2023-12-01T15:49:57.820337Z","shell.execute_reply":"2023-12-01T15:49:57.824268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df = pd.read_csv(\"../input/nfl-player-numbers/train_player_numbers.csv\")\ndataset_df","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:49:57.827169Z","iopub.execute_input":"2023-12-01T15:49:57.827519Z","iopub.status.idle":"2023-12-01T15:49:58.024980Z","shell.execute_reply.started":"2023-12-01T15:49:57.827484Z","shell.execute_reply":"2023-12-01T15:49:58.024144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_df = dataset_df.sample(frac=1).reset_index(drop=True)\ndataset_df[\"filepath\"] = [\"../input/nfl-player-numbers/\"+row.filepath for idx, row in dataset_df.iterrows()]\ndataset_df = dataset_df[dataset_df.video_frame.str.contains(\"Endzone\")]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:49:58.026461Z","iopub.execute_input":"2023-12-01T15:49:58.026745Z","iopub.status.idle":"2023-12-01T15:50:02.161471Z","shell.execute_reply.started":"2023-12-01T15:49:58.026716Z","shell.execute_reply":"2023-12-01T15:50:02.160637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"markdown","source":"The training process used below is heavily inspired from one of my previous notebooks available [here](https://www.kaggle.com/frlemarchand/efficientnet-aug-tf-keras-for-cassava-diseases). Please note that I should have probably split my dataset based on the playID as some frames within the same play can be extremely similar.","metadata":{}},{"cell_type":"code","source":"training_percentage = 0.75\ntraining_item_count = int(len(dataset_df)*training_percentage)\nvalidation_item_count = len(dataset_df)-int(len(dataset_df)*training_percentage)\ntraining_df = dataset_df[:training_item_count]\nvalidation_df = dataset_df[training_item_count:]","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:02.162814Z","iopub.execute_input":"2023-12-01T15:50:02.163204Z","iopub.status.idle":"2023-12-01T15:50:02.167962Z","shell.execute_reply.started":"2023-12-01T15:50:02.163166Z","shell.execute_reply":"2023-12-01T15:50:02.167144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nimage_size = 64\ninput_shape = (image_size, image_size, 3)\ndropout_rate = 0.3\nclasses_to_predict = sorted(training_df.label.unique())\nclass_weights = class_weight.compute_class_weight(\"balanced\", classes_to_predict, training_df.label.values)\nclass_weights_dict = {i : class_weights[i] for i,label in enumerate(classes_to_predict)}\n\ntraining_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:02.169036Z","iopub.execute_input":"2023-12-01T15:50:02.169302Z","iopub.status.idle":"2023-12-01T15:50:04.018883Z","shell.execute_reply.started":"2023-12-01T15:50:02.169275Z","shell.execute_reply":"2023-12-01T15:50:04.017915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image_and_label_from_path(image_path, label):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntraining_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\nvalidation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n\ntraining_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalidation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:04.020038Z","iopub.execute_input":"2023-12-01T15:50:04.020344Z","iopub.status.idle":"2023-12-01T15:50:04.114260Z","shell.execute_reply.started":"2023-12-01T15:50:04.020314Z","shell.execute_reply":"2023-12-01T15:50:04.113541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomRotation(0.25),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:04.116551Z","iopub.execute_input":"2023-12-01T15:50:04.116835Z","iopub.status.idle":"2023-12-01T15:50:04.461102Z","shell.execute_reply.started":"2023-12-01T15:50:04.116808Z","shell.execute_reply":"2023-12-01T15:50:04.460335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = Image.open(training_df.filepath.values[10])\nplt.imshow(image)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:04.462827Z","iopub.execute_input":"2023-12-01T15:50:04.463129Z","iopub.status.idle":"2023-12-01T15:50:04.628097Z","shell.execute_reply.started":"2023-12-01T15:50:04.463095Z","shell.execute_reply":"2023-12-01T15:50:04.627089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = tf.expand_dims(np.array(image), 0)\nplt.figure(figsize=(10, 10))\nfor i in range(4):\n    augmented_image = data_augmentation_layers(image)\n    ax = plt.subplot(2, 2, i + 1)\n    plt.imshow(augmented_image[0])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:04.629461Z","iopub.execute_input":"2023-12-01T15:50:04.629794Z","iopub.status.idle":"2023-12-01T15:50:05.227919Z","shell.execute_reply.started":"2023-12-01T15:50:04.629763Z","shell.execute_reply":"2023-12-01T15:50:05.227070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efficientnet = EfficientNetB0(weights=\"../input/efficientnet-b0-for-keras-no-top/efficientnetb0_notop.h5\", \n                              include_top=False, \n                              input_shape=input_shape, \n                              drop_connect_rate=dropout_rate)\n\ninputs = Input(shape=input_shape)\naugmented = data_augmentation_layers(inputs)\nefficientnet = efficientnet(augmented)\npooling = layers.GlobalAveragePooling2D()(efficientnet)\ndropout = layers.Dropout(dropout_rate)(pooling)\noutputs = Dense(len(classes_to_predict), activation=\"softmax\")(dropout)\nmodel = Model(inputs=inputs, outputs=outputs)\n    \nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:05.229118Z","iopub.execute_input":"2023-12-01T15:50:05.229398Z","iopub.status.idle":"2023-12-01T15:50:07.965998Z","shell.execute_reply.started":"2023-12-01T15:50:05.229369Z","shell.execute_reply":"2023-12-01T15:50:07.965184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 25\ndecay_steps = int(round(len(training_df)/batch_size))*epochs\ncosine_decay = CosineDecay(initial_learning_rate=1e-3, decay_steps=decay_steps, alpha=0.3)\n\ncallbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:07.967072Z","iopub.execute_input":"2023-12-01T15:50:07.967347Z","iopub.status.idle":"2023-12-01T15:50:07.986948Z","shell.execute_reply.started":"2023-12-01T15:50:07.967320Z","shell.execute_reply":"2023-12-01T15:50:07.986202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(training_data_batches,\n                  epochs = epochs, \n                  validation_data=validation_data_batches,\n                  class_weight=class_weights_dict,\n                  callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:50:07.988112Z","iopub.execute_input":"2023-12-01T15:50:07.988470Z","iopub.status.idle":"2023-12-01T15:56:59.644543Z","shell.execute_reply.started":"2023-12-01T15:50:07.988434Z","shell.execute_reply":"2023-12-01T15:56:59.643692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(\"best_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:56:59.646011Z","iopub.execute_input":"2023-12-01T15:56:59.646302Z","iopub.status.idle":"2023-12-01T15:56:59.832510Z","shell.execute_reply.started":"2023-12-01T15:56:59.646273Z","shell.execute_reply":"2023-12-01T15:56:59.831453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract videos frames from test set","metadata":{}},{"cell_type":"code","source":"def mk_images(video_name, video_labels, video_dir, out_dir, only_with_impact=True):\n    video_path=f\"{video_dir}/{video_name}\"\n    video_name = os.path.basename(video_path)\n    vidcap = cv.VideoCapture(video_path)\n    if only_with_impact:\n        boxes_all = video_labels.query(\"video == @video_name\")\n        print(video_path, boxes_all[boxes_all.impact == 1.0].shape[0])\n    else:\n        print(video_path)\n    frame = 0\n\n    while True:\n        it_worked, img = vidcap.read()\n        if not it_worked:\n            break\n        frame += 1\n        if only_with_impact:\n            boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n            boxes_with_impact = boxes[boxes.impact == 1.0]\n            if boxes_with_impact.shape[0] == 0:\n                continue\n        img_name = f\"{video_name}_frame{frame}\"\n        image_path = f'{out_dir}/{video_name}'.replace('.mp4',f'_{frame}.png')\n\n        try:\n            _ = cv.imwrite(image_path, img)\n        except:\n            print(img_name+\" \"+image_path)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:56:59.833816Z","iopub.execute_input":"2023-12-01T15:56:59.834117Z","iopub.status.idle":"2023-12-01T15:56:59.842872Z","shell.execute_reply.started":"2023-12-01T15:56:59.834087Z","shell.execute_reply":"2023-12-01T15:56:59.841959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_frames_folder = \"../working/test_frames\"\nos.mkdir(test_frames_folder)\n\nvideo_dir = '../input/nfl-health-and-safety-helmet-assignment/test'\nvideo_folder = [filename for filename in os.listdir(video_dir)]\nfor video_name in video_folder:\n    print(video_name)\n    mk_images(video_name, pd.DataFrame(), video_dir, test_frames_folder, only_with_impact=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:56:59.844107Z","iopub.execute_input":"2023-12-01T15:56:59.844393Z","iopub.status.idle":"2023-12-01T15:59:14.586658Z","shell.execute_reply.started":"2023-12-01T15:56:59.844366Z","shell.execute_reply":"2023-12-01T15:59:14.585849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Recognise jersey numbers in new video frames","metadata":{}},{"cell_type":"code","source":"test_helmet_df = pd.read_csv(\"../input/nfl-health-and-safety-helmet-assignment/test_baseline_helmets.csv\")\ntest_tracking_df = pd.read_csv(\"../input/nfl-health-and-safety-helmet-assignment/test_player_tracking.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:59:14.587905Z","iopub.execute_input":"2023-12-01T15:59:14.588228Z","iopub.status.idle":"2023-12-01T15:59:14.711692Z","shell.execute_reply.started":"2023-12-01T15:59:14.588199Z","shell.execute_reply":"2023-12-01T15:59:14.710896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:59:14.712771Z","iopub.execute_input":"2023-12-01T15:59:14.713055Z","iopub.status.idle":"2023-12-01T15:59:14.716797Z","shell.execute_reply.started":"2023-12-01T15:59:14.713026Z","shell.execute_reply":"2023-12-01T15:59:14.715915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_team(jersey_number, video_frame_name):\n    '''\n    find to which team a player belong based on the jersey number\n    return None if we have 2 players with the same number on the pitch\n    '''\n    \n    game_id = int(video_frame_name.split(\"_\")[0])\n    play_id = int(video_frame_name.split(\"_\")[1])\n    player_list = test_tracking_df.query(\"gameKey==@game_id and playID==@play_id\").player.unique()\n    possible_players = [player_code for player_code in player_list if jersey_number==int(player_code[1:])]\n\n    if len(possible_players)==1:\n        return possible_players[0]\n    else:\n        return None\n\ndef extract_player_jersey(video_frame_name, display=False):\n    \n    #Get the helmet boxes for a frame and apply the model.\n    #If a player is predicted twice, keeps the prediction\n    #with the highest confidence score.\n    \n    predictions = []\n    img = np.array(Image.open(test_frames_folder+\"/\"+str(video_frame_name)))\n    frame_df = test_helmet_df[test_helmet_df[\"video_frame\"]==video_frame_name.replace(\".png\",\"\")]\n\n    baseline_boxes = np.array([np.array([row.left, row.top, row.left+row.width, row.top+row.height ])  for idx, row in frame_df.iterrows()])\n    for idx, box in enumerate(baseline_boxes):\n        box_centre = int(box[0]+round((box[2]-box[0])/2))\n        jersey_box = img[box[3]-24:box[3]+40,box_centre-32:box_centre+32,:]\n        \n        if jersey_box.shape==(64,64,3):\n            result = model.predict(np.array([np.array(jersey_box)]))\n            predicted_jersey_number = np.argmax(result)\n            confidence = result[0][np.argmax(result)] \n            confidence_threshold = 0.90\n\n            if confidence>confidence_threshold:\n                predicted_player_code = find_team(predicted_jersey_number, video_frame_name)\n                \n                if predicted_player_code is not None:\n                    player_already_detected = [(i, item) for i, item in enumerate(predictions) if item[\"label\"] == predicted_player_code]\n                    prediction_data = {\"video_frame\":video_frame_name.replace(\".png\",\"\"), \n                                            \"label\":predicted_player_code,\n                                            \"left\":frame_df.iloc[idx].left,\n                                            \"width\":frame_df.iloc[idx].width,\t\n                                            \"top\":frame_df.iloc[idx].top,\n                                            \"height\":frame_df.iloc[idx].height,\n                                            \"confidence\":confidence}\n                    \n                    if player_already_detected==[]:\n                        predictions.append(prediction_data)\n                    else:\n                        if player_already_detected[0][1]['confidence']<confidence:\n                            dict_index_to_remove = player_already_detected[0][0]\n                            del predictions[dict_index_to_remove]\n                            predictions.append(prediction_data)\n                    \n                    if display:\n                        print(predicted_player_code, confidence)\n\n                        # Draw bounding box on the image\n                        cv2.rectangle(img, (int(prediction_data[\"left\"]), int(prediction_data[\"top\"])),\n                                      (int(prediction_data[\"left\"] + prediction_data[\"width\"]),\n                                       int(prediction_data[\"top\"] + prediction_data[\"height\"])),\n                                      (0, 255, 0), 2)\n\n                        # Add text with jersey number and confidence\n                        label_text = f'Player: {predicted_player_code}\\nConfidence: {confidence:.2f}'\n                        cv2.putText(img, label_text, (int(prediction_data[\"left\"]), int(prediction_data[\"top\"] - 10)),\n                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1, cv2.LINE_AA)\n\n                        plt.imshow(img)\n                        plt.show()\n        \n    return predictions\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-12-01T16:46:38.653494Z","iopub.execute_input":"2023-12-01T16:46:38.653875Z","iopub.status.idle":"2023-12-01T16:46:38.680555Z","shell.execute_reply.started":"2023-12-01T16:46:38.653841Z","shell.execute_reply":"2023-12-01T16:46:38.679526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_player(video_frame_name, display=False):\n    '''\n    Get the helmet boxes for a frame and apply the model.\n    If a player is predicted twice, keeps the prediction\n    with the highest confidence score.\n    '''\n    \n    predictions = []\n    img = np.array(Image.open(test_frames_folder+\"/\"+str(video_frame_name)))\n    frame_df = test_helmet_df[test_helmet_df[\"video_frame\"]==video_frame_name.replace(\".png\",\"\")]\n\n    baseline_boxes = np.array([np.array([row.left, row.top, row.left+row.width, row.top+row.height ])  for idx, row in frame_df.iterrows()])\n    for idx, box in enumerate(baseline_boxes):\n        box_centre = int(box[0]+round((box[2]-box[0])/2))\n        jersey_box = img[box[3]-24:box[3]+40,box_centre-32:box_centre+32,:]\n        \n        if jersey_box.shape==(64,64,3):\n            result = model.predict(np.array([np.array(jersey_box)]))\n            predicted_jersey_number = np.argmax(result)\n            confidence = result[0][np.argmax(result)] \n            confidence_threshold = 0.90\n\n            if confidence>confidence_threshold:\n                predicted_player_code = find_team(predicted_jersey_number, video_frame_name)\n                \n                if predicted_player_code is not None:\n                    player_already_detected = [(i, item) for i, item in enumerate(predictions) if item[\"label\"] == predicted_player_code]\n                    prediction_data = {\"video_frame\":video_frame_name.replace(\".png\",\"\"), \n                                            \"label\":predicted_player_code,\n                                            \n                                            \"confidence\":confidence}\n                    \n                    if player_already_detected==[]:\n                        predictions.append(prediction_data)\n                    else:\n                        if player_already_detected[0][1]['confidence']<confidence:\n                            dict_index_to_remove = player_already_detected[0][0]\n                            del predictions[dict_index_to_remove]\n                            predictions.append(prediction_data)\n                    \n                    if display:\n                        print(predicted_player_code, confidence)\n                        plt.imshow(jersey_box)\n                        plt.show()\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-12-01T16:43:31.764450Z","iopub.execute_input":"2023-12-01T16:43:31.764822Z","iopub.status.idle":"2023-12-01T16:43:31.778088Z","shell.execute_reply.started":"2023-12-01T16:43:31.764793Z","shell.execute_reply":"2023-12-01T16:43:31.777180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For this run, we'll only apply prediction on the frames taken from the endzone as the jerseys are often easier to see.","metadata":{}},{"cell_type":"code","source":"frame_list = os.listdir(test_frames_folder)\nframe_list = [x for x in frame_list if \"Endzone\" in x]\nrandom.seed(42)\n#frames_to_test = random.sample(frame_list, 6) ","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:59:14.756655Z","iopub.execute_input":"2023-12-01T15:59:14.756918Z","iopub.status.idle":"2023-12-01T15:59:14.769659Z","shell.execute_reply.started":"2023-12-01T15:59:14.756892Z","shell.execute_reply":"2023-12-01T15:59:14.768743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[1], display=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:59:14.770866Z","iopub.execute_input":"2023-12-01T15:59:14.771263Z","iopub.status.idle":"2023-12-01T15:59:17.753609Z","shell.execute_reply.started":"2023-12-01T15:59:14.771224Z","shell.execute_reply":"2023-12-01T15:59:17.752720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = random.randint(1,100)\nprint(x)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nextract_player_jersey(frame_list[x], display=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T16:46:42.115619Z","iopub.execute_input":"2023-12-01T16:46:42.115949Z","iopub.status.idle":"2023-12-01T16:46:43.536968Z","shell.execute_reply.started":"2023-12-01T16:46:42.115922Z","shell.execute_reply":"2023-12-01T16:46:43.536092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player(frame_list[x], display=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-01T16:43:36.645610Z","iopub.execute_input":"2023-12-01T16:43:36.645959Z","iopub.status.idle":"2023-12-01T16:43:37.702869Z","shell.execute_reply.started":"2023-12-01T16:43:36.645928Z","shell.execute_reply":"2023-12-01T16:43:37.702054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[random.randint(1, 100)], display=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:40:51.783967Z","iopub.execute_input":"2023-12-01T15:40:51.784347Z","iopub.status.idle":"2023-12-01T15:40:53.117009Z","shell.execute_reply.started":"2023-12-01T15:40:51.784307Z","shell.execute_reply":"2023-12-01T15:40:53.116114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[random.randint(1, 100)], display=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:40:53.118211Z","iopub.execute_input":"2023-12-01T15:40:53.118500Z","iopub.status.idle":"2023-12-01T15:40:55.287591Z","shell.execute_reply.started":"2023-12-01T15:40:53.118470Z","shell.execute_reply":"2023-12-01T15:40:55.286775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[random.randint(1, 100)], display=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:40:55.290899Z","iopub.execute_input":"2023-12-01T15:40:55.291172Z","iopub.status.idle":"2023-12-01T15:40:56.136989Z","shell.execute_reply.started":"2023-12-01T15:40:55.291146Z","shell.execute_reply":"2023-12-01T15:40:56.136079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[random.randint(1, 100)], display=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:40:56.138811Z","iopub.execute_input":"2023-12-01T15:40:56.139201Z","iopub.status.idle":"2023-12-01T15:40:57.214021Z","shell.execute_reply.started":"2023-12-01T15:40:56.139162Z","shell.execute_reply":"2023-12-01T15:40:57.213119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extract_player_jersey(frame_list[random.randint(1, 100)], display=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-01T15:40:57.215402Z","iopub.execute_input":"2023-12-01T15:40:57.215817Z","iopub.status.idle":"2023-12-01T15:40:58.187782Z","shell.execute_reply.started":"2023-12-01T15:40:57.215777Z","shell.execute_reply":"2023-12-01T15:40:58.186923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have created the function to submit the predictions but it's still early days to be spamming the leaderboard yet!","metadata":{}}]}